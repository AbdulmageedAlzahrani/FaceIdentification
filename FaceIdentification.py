# -*- coding: utf-8 -*-
"""Untitled31.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WkUjwW9209t9J2-4r2Zx4yY6Ne-h6wfv
"""

from google.colab import drive
import cv2
import matplotlib.pyplot as plt

!pip install face_recognition

import face_recognition
import cv2

drive.mount("/content/gdrive")

import os
import numpy as np
from PIL import Image
import torchvision.transforms as transforms
import torch
import torchvision   
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import models
import time

!unrar x "/content/gdrive/MyDrive/HW4_Data.rar"

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet152', pretrained=True)

num_workers = 4
transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])

train_dataset = torchvision.datasets.ImageFolder(root='HW4_Data/classification_data/train_data/', 
                                                 transform=transform)
train_dataloader = DataLoader(train_dataset, batch_size=32, 
                                               shuffle=True, num_workers=num_workers)

val_dataset = torchvision.datasets.ImageFolder(root='HW4_Data/classification_data/val_data/', 
                                                 transform=transform)
val_dataloader = DataLoader(val_dataset, batch_size=32, 
                                               shuffle=True, num_workers=num_workers)

test_dataset = torchvision.datasets.ImageFolder(root='HW4_Data/classification_data/test_data/', 
                                                 transform=transform)
test_dataloader = DataLoader(test_dataset, batch_size=32, 
                                               shuffle=False, num_workers=num_workers)
print(len(train_dataset))

model.fc = nn.Linear(in_features=2048, out_features=4000, bias=True)
print(model)
model.to(device)
# optimizer
optimizer = torch.optim.SGD(model.parameters(), lr=0.005, momentum=0.9)
# loss function
criterion = nn.CrossEntropyLoss()

def train(model, data_loader, test_loader, nextEpoch = 0, task='Classification'):
    model.train()
    for epoch in range(numEpochs):
        start_time = time.time()
        avg_loss = 0.0
        for batch_num, (feats, labels) in enumerate(data_loader):
            feats, labels = feats.to(device), labels.to(device)
            
            optimizer.zero_grad()
            outputs = model(feats)
            loss = criterion(outputs, labels.long())
            loss.backward()
            optimizer.step()
            
            avg_loss += loss.item()
            everyB = 200
            if batch_num % everyB == (everyB-1):
                print('Epoch: {}\tBatch: {}\tAvg-Loss: {:.4f}'.format(epoch+1+nextEpoch, batch_num+1, avg_loss/everyB))
                avg_loss = 0.0    
            
            torch.cuda.empty_cache()
            del feats
            del labels
            del loss
        
        if task == 'Classification':
            val_loss, val_acc = test_classify(model, test_loader)
            train_loss, train_acc = test_classify(model, data_loader)
            print('Train Loss: {:.4f}\tTrain Accuracy: {:.4f}\tVal Loss: {:.4f}\tVal Accuracy: {:.4f}'.
                  format(train_loss, train_acc, val_loss, val_acc))
        else:
            test_verify(model, test_loader)
        
        end_time = time.time()
        print('Time: ',end_time - start_time, 's')

        torch.save({
            'epoch': (epoch+nextEpoch),
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict()}, '/content/gdrive/MyDrive/modelRe'+(str)(epoch+nextEpoch)+'.pt')

def test_classify(model, test_loader):
    model.eval()
    test_loss = []
    accuracy = 0
    total = 0

    for batch_num, (feats, labels) in enumerate(test_loader):
        feats, labels = feats.to(device), labels.to(device)
        outputs = model(feats)
              
        _, pred_labels = torch.max(F.softmax(outputs, dim=1), 1)
        pred_labels = pred_labels.view(-1)
        
        everyB = 400
        # if batch_num % everyB == (everyB-1):
        #     print('Test Batch: {}'.format(batch_num+1))
        
        loss = criterion(outputs, labels.long())
        accuracy += torch.sum(torch.eq(pred_labels, labels)).item()
        total += len(labels)
        test_loss.extend([loss.item()]*feats.size()[0])
        del feats
        del labels
    
    model.train()
    return np.mean(test_loss), accuracy/total


def test_verify(model, test_loader):
    raise NotImplementedError

numEpochs = 5
print(len(train_dataset))
train(model, train_dataloader, val_dataloader)

def readFile():
  f = open('HW4_Data/verification_pairs_val.txt','r')
  pairs = []
  values = []
  for line in f:
    a = line.strip().split(' ')
    pairs += [[a[0],a[1]]]
    values += a[2]

  f.close()
  return pairs, values

pairs, values =readFile()

model.fc = nn.Sequential()
model.eval()
model.to(device)
print(model)

def verification(model, pairs, values):
  transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
  ])

  scores = []
  for i in range(len(pairs)):
    if i%600 ==0:
      print(i)
    img1 = Image.open('HW4_Data/'+pairs[i][0])
    img1 = transform(img1)
    img1 = img1.unsqueeze(0)
    img1 = img1.to(device)

    img2 = Image.open('HW4_Data/'+pairs[i][1])
    img2 = transform(img2)
    img2 = img2.unsqueeze(0)
    img2 = img2.to(device)

    out1 = model(img1)
    out2 = model(img2)
    y = torch.nn.functional.cosine_similarity(out1[0], out2[0], dim=-1, eps=1e-8)
    scores += [y.item()]

  return scores

scores = verification(model, pairs, values)

from sklearn.metrics import roc_auc_score
from sklearn.metrics import accuracy_score
auc = roc_auc_score(values, scores)
print("AUC score:", auc)

results = []
for i in range(len(scores)):
  if scores[i] > 0.6:
    results += [1]
  else:
    results += [0]

for i in range(len(values)):
  values[i] = (int)(values[i])

acc = accuracy_score(values, results)
print("Verification Accuracy (with choosing threshold = 0.6):", acc)

!pip install face_recognition

import face_recognition
import cv2

def displayImage(img):
    # Show image
    plt.figure(figsize = (5,5))
    plt.imshow(img)
    plt.axis('off')
    plt.show()

path = 'sample.jpg'
path2 = '0004_01.jpg'

image = face_recognition.load_image_file(path)
displayImage(image)

face_locations = face_recognition.face_locations(image, model="hog")

img = image.copy()
for (top,right,bottom,left) in face_locations:
    face = img[top:bottom,left:right,:]
    print(top,right,bottom,left)
    print(face.shape)
    displayImage(face)

resize_face = cv2.resize(face, (64,64), interpolation = cv2.INTER_AREA)
displayImage(resize_face)

image2 = face_recognition.load_image_file(path2)
displayImage(image2)

face_locations = face_recognition.face_locations(image2, model="hog")

img = image2.copy()
for (top,right,bottom,left) in face_locations:
    face2 = img[top:bottom,left:right,:]
    displayImage(face2)

resize_face2 = cv2.resize(face2, (64,64), interpolation = cv2.INTER_AREA)
displayImage(resize_face2)

from PIL import Image
from matplotlib import cm
img1 = Image.fromarray(resize_face)
img2 = Image.fromarray(resize_face2)

img1 = transform(img1)
img1 = img1.unsqueeze(0)
img1 = img1.to(device)

img2 = transform(img2)
img2 = img2.unsqueeze(0)
img2 = img2.to(device)

out1 = model(img1)
out2 = model(img2)

y = torch.nn.functional.cosine_similarity(out1[0], out2[0], dim=-1, eps=1e-8)

print(y.item()>0.6)

